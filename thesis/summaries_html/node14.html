<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2008 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>A convolutional neural network approach for objective video quality assessment [5] </TITLE>
<META NAME="description" CONTENT="A convolutional neural network approach for objective video quality assessment [5] ">
<META NAME="keywords" CONTENT="summaries">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2008">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="summaries.css">

<LINK REL="next" HREF="node15.html">
<LINK REL="previous" HREF="node13.html">
<LINK REL="up" HREF="summaries.html">
<LINK REL="next" HREF="node15.html">
</HEAD>

<BODY text="#000000" bgcolor="#FFFFFF">
<!--Navigation Panel-->
<A NAME="tex2html463"
  HREF="node15.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html459"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html453"
  HREF="node13.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html461"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html464"
  HREF="node15.html">A fast learning algorithm</A>
<B> Up:</B> <A NAME="tex2html460"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html454"
  HREF="node13.html">Best Practices for Convolutional</A>
 &nbsp; <B>  <A NAME="tex2html462"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html465"
  HREF="node14.html#SECTION000141000000000000000">Original Abstract</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION000140000000000000000">
A convolutional neural network approach for objective video quality assessment [<A
 HREF="node55.html#Callet2006">5</A>] </A>
</H1>

<H2><A NAME="SECTION000141000000000000000">
Original Abstract</A>
</H2>

<P>
<I>
This paper describes an application of neural networks in the field of objective measurement method designed to automatically assess the perceived quality of digital videos. This challenging issue aims to emulate human judgment and to replace very complex and time consuming subjective quality assessment. Several metrics have been proposed in literature to tackle this issue. They are based on a general framework that combines different stages, each of them addressing complex problems. The ambition of this paper is not to present a global perfect quality metric but rather to focus on an original way to use neural networks in such a framework in the context of reduced reference (RR) quality metric. Especially, we point out the interest of such a tool for combining features and pooling them in order to compute quality scores. The proposed approach solves some problems inherent to objective metrics that should predict subjective quality score obtained using the single stimulus continuous quality evaluation (SSCQE) method. This latter has been adopted by video quality expert group (VQEG) in its recently finalized reduced referenced and no reference (RRNR-TV) test plan. The originality of such approach compared to previous attempts to use neural networks for quality assessment, relies on the use of a convolutional neural network (CNN) that allows a continuous time scoring of the video. Objective features are extracted on a frame-by-frame basis on both the reference and the distorted sequences; they are derived from a perceptual-based representation and integrated along the temporal axis using a time-delay neural network (TDNN). Experiments conducted on different MPEG-2 videos, with bit rates ranging 2-6 Mb/s, show the effectiveness of the proposed approach to get a plausible model of temporal pooling from the human vision system (HVS) point of view. More specifically, a linear correlation criteria, between objective and subjective scoring, up to 0.92 has been obtained on a- - set of typical TV videos
</I>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html463"
  HREF="node15.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html459"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html453"
  HREF="node13.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html461"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html464"
  HREF="node15.html">A fast learning algorithm</A>
<B> Up:</B> <A NAME="tex2html460"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html454"
  HREF="node13.html">Best Practices for Convolutional</A>
 &nbsp; <B>  <A NAME="tex2html462"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
Miquel Perello Nieto
2014-05-14
</ADDRESS>
</BODY>
</HTML>
