<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2008 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video [51] </TITLE>
<META NAME="description" CONTENT="Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video [51] ">
<META NAME="keywords" CONTENT="summaries">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2008">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="summaries.css">

<LINK REL="next" HREF="node49.html">
<LINK REL="previous" HREF="node47.html">
<LINK REL="up" HREF="summaries.html">
<LINK REL="next" HREF="node49.html">
</HEAD>

<BODY text="#000000" bgcolor="#FFFFFF">
<!--Navigation Panel-->
<A NAME="tex2html923"
  HREF="node49.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html919"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html913"
  HREF="node47.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html921"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html924"
  HREF="node49.html">Learned versus Hand-Designed Feature</A>
<B> Up:</B> <A NAME="tex2html920"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html914"
  HREF="node47.html">MediaMill at TRECVID 2013:</A>
 &nbsp; <B>  <A NAME="tex2html922"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html925"
  HREF="node48.html#SECTION000481000000000000000">Original Abstract</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION000480000000000000000">
Semi-supervised Learning of Feature Hierarchies for Object Detection in a Video [<A
 HREF="node55.html#Yang2013">51</A>] </A>
</H1>

<H2><A NAME="SECTION000481000000000000000">
Original Abstract</A>
</H2>

<P>
<I>
We propose a novel approach to boost the performance of generic object detectors on videos by learning video-specific features using a deep neural network. The insight behind our proposed approach is that an object appearing in different frames of a video clip should share similar features, which can be learned to build better detectors. Unlike many supervised detector adaptation or detection-by-tracking methods, our method does not require any extra annotations or utilize temporal correspondence. We start with the high-confidence detections from a generic detector, then iteratively learn new video-specific features and refine the detection scores. In order to learn discriminative and compact features, we propose a new feature learning method using a deep neural network based on auto en-coders. It differs from the existing unsupervised feature learning methods in two ways: first it optimizes both discriminative and generative properties of the features simultaneously, which gives our features better discriminative ability, second, our learned features are more compact, while the unsupervised feature learning methods usually learn a redundant set of over-complete features. Extensive experimental results on person and horse detection show that significant performance improvement can be achieved with our proposed method.
</I>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html923"
  HREF="node49.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html919"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html913"
  HREF="node47.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html921"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html924"
  HREF="node49.html">Learned versus Hand-Designed Feature</A>
<B> Up:</B> <A NAME="tex2html920"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html914"
  HREF="node47.html">MediaMill at TRECVID 2013:</A>
 &nbsp; <B>  <A NAME="tex2html922"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
Miquel Perello Nieto
2014-05-14
</ADDRESS>
</BODY>
</HTML>
