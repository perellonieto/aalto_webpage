<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2008 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position [12] </TITLE>
<META NAME="description" CONTENT="Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position [12] ">
<META NAME="keywords" CONTENT="summaries">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2008">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="summaries.css">

<LINK REL="next" HREF="node6.html">
<LINK REL="previous" HREF="node4.html">
<LINK REL="up" HREF="summaries.html">
<LINK REL="next" HREF="node6.html">
</HEAD>

<BODY text="#000000" bgcolor="#FFFFFF">
<!--Navigation Panel-->
<A NAME="tex2html339"
  HREF="node6.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html335"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html329"
  HREF="node4.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html337"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html340"
  HREF="node6.html">Generalization and network design</A>
<B> Up:</B> <A NAME="tex2html336"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html330"
  HREF="node4.html">Receptive fields and functional</A>
 &nbsp; <B>  <A NAME="tex2html338"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html341"
  HREF="node5.html#SECTION00051000000000000000">Original Abstract</A>
<LI><A NAME="tex2html342"
  HREF="node5.html#SECTION00052000000000000000">Main points</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION00050000000000000000">
Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position [<A
 HREF="node55.html#Fukushima1980">12</A>] </A>
</H1>

<H2><A NAME="SECTION00051000000000000000">
Original Abstract</A>
</H2>

<P>
<I>
A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells', which show charac- teristics similar to simple cells or lower order hyper- complex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self- organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern. 1.
</I>

<H2><A NAME="SECTION00052000000000000000">
Main points</A>
</H2>

<P>

<UL>
<LI>Reiteration of self-organized by ''learning without a teacher''
</LI>
<LI>Similar structure to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel.
</LI>
<LI>Network structure:
      
<UL>
<LI>Input layer (photoreceptor array)
</LI>
<LI>Cascade of modules each one with :
          
<UL>
<LI>S-cells: in the first layer Simple cells or lower order hypercomplex cells
</LI>
<LI>C-cells: in the second layer Complex cells or higher order hypercomplex cells
          
</LI>
</UL>
</LI>
</UL>
</LI>
<LI>Hubel and Wiesel : the neural network in the visual cortex has a hierarchy structure:
      
<UL>
<LI>LGB (Lageral Geniculate Body)
</LI>
<LI>Simple cells
</LI>
<LI>Complex cells
</LI>
<LI>Lower order hypercomplex cells
</LI>
<LI>Higher order hypercomplex cells
      
</LI>
</UL>
</LI>
<LI>a cell in a higher stage generally has tendency to respond selectively to a more complicated feature of the stimulus pattern
</LI>
<LI>we extend the hierarchy model of Hubel and Wiesel, and <B>hypothesize</B> the existance of a similar hierarchy structure even in hte stages higher than hypercomplex cells.
</LI>
<LI>In the last module, the receptive field of each C-cell becomes so large as to cover the whole area of input layer , and each C-plane is so determined as to have only one C-cell
</LI>
<LI>The output of an S-cell in the -th S-plane in the l-th module is described below

<P>
</LI>
</UL><HR>
<!--Navigation Panel-->
<A NAME="tex2html339"
  HREF="node6.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/next.gif"></A> 
<A NAME="tex2html335"
  HREF="summaries.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/up.gif"></A> 
<A NAME="tex2html329"
  HREF="node4.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/prev.gif"></A> 
<A NAME="tex2html337"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="https://users.ics.aalto.fi/perellm1/images/icons/contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html340"
  HREF="node6.html">Generalization and network design</A>
<B> Up:</B> <A NAME="tex2html336"
  HREF="summaries.html">Summary of References Related</A>
<B> Previous:</B> <A NAME="tex2html330"
  HREF="node4.html">Receptive fields and functional</A>
 &nbsp; <B>  <A NAME="tex2html338"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
Miquel Perello Nieto
2014-05-14
</ADDRESS>
</BODY>
</HTML>
